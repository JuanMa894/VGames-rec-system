{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Video Game Recomendation System"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Business understanding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data understanding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset from kaggle on [here](https://www.kaggle.com/datasets/cynthiarempel/amazon-us-customer-reviews-dataset?select=amazon_reviews_us_Digital_Video_Games_v1_00.tsv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 144724 entries, 0 to 144723\n",
      "Data columns (total 15 columns):\n",
      " #   Column             Non-Null Count   Dtype \n",
      "---  ------             --------------   ----- \n",
      " 0   marketplace        144724 non-null  object\n",
      " 1   customer_id        144724 non-null  int64 \n",
      " 2   review_id          144724 non-null  object\n",
      " 3   product_id         144724 non-null  object\n",
      " 4   product_parent     144724 non-null  int64 \n",
      " 5   product_title      144724 non-null  object\n",
      " 6   product_category   144724 non-null  object\n",
      " 7   star_rating        144724 non-null  int64 \n",
      " 8   helpful_votes      144724 non-null  int64 \n",
      " 9   total_votes        144724 non-null  int64 \n",
      " 10  vine               144724 non-null  object\n",
      " 11  verified_purchase  144724 non-null  object\n",
      " 12  review_headline    144722 non-null  object\n",
      " 13  review_body        144722 non-null  object\n",
      " 14  review_date        144721 non-null  object\n",
      "dtypes: int64(5), object(10)\n",
      "memory usage: 16.6+ MB\n"
     ]
    }
   ],
   "source": [
    "df_raw = pd.read_csv('./data/Digital_Video_Games.tsv', sep='\\t', header=0, error_bad_lines=False)\n",
    "df_raw.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Columns\n",
    "- **marketplace**: 2 letter country code of the marketplace where the review was written.\n",
    "- **customer_id**: Random identifier that can be used to aggregate reviews written by a single author.\n",
    "- **review_id**: The unique ID of the review.\n",
    "- **productid**: The unique Product ID the review pertains to. In the multilingual dataset the reviews for the same product in different countries can be grouped by the same productid.\n",
    "- **product_parent**: Random identifier that can be used to aggregate reviews for the same product.\n",
    "- **product_title**: Title of the product.\n",
    "- **product_category**: Broad product category that can be used to group reviews (also used to group the dataset into coherent parts).\n",
    "- **star_rating**: The 1-5 star rating of the review.\n",
    "- **helpful_votes**: Number of helpful votes.\n",
    "- **total_votes**: Number of total votes the review received.\n",
    "- **vine**: Review was written as part of the Vine program.\n",
    "- **verified_purchase**: The review is on a verified purchase.\n",
    "- **review_headline**: The title of the review.\n",
    "- **review_body**: The review text.\n",
    "- **review_date**: The date the review was written."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['US'], dtype=object)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_raw['marketplace'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All reviews in dataset are from US customers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "112891"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_raw['customer_id'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "112891 different customers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "144724"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_raw['review_id'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seems like there are no duplicate reviews in the set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7939"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_raw['product_id'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7939 different products, but not all video games, found \"Playstation Plus Subscription\" in row 3, so all digitally sold products related video games, like subscriptions, seem to be included in the data set, will further look for other kind of product other than games and drop those."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7755"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_raw['product_parent'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **product_parent**: Random identifier that can be used to aggregate reviews for the same product.\n",
    "\n",
    "seems like just another id but we have about 200 less data points in this column than product id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6946"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_raw['product_title'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If i have 6946 different titles, i would expect the same amount of product_id, wonder if by droping everything that is not a game, like substriptions, would fix this discrepancy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Playstation Plus Subscription'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_raw.iloc[3]['product_title']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It doesnt specify if the subscription is for 1, 3 or 12 months\n",
    "\n",
    "<br>\n",
    "\n",
    "Below i used key words to look for any products that is not a game\n",
    "e.g\n",
    "- Subscription\n",
    "- Month\n",
    "- Membership\n",
    "- Card\n",
    "- Network\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of reviews for \"Subscription\" items: 12137 \n",
      "\n",
      "Number of reviews for \"Month\" items: 630 \n",
      "\n",
      "Number of reviews for \"Membership\" items: 275 \n",
      "\n",
      "Number of reviews for \"Card\" items: 21173 \n",
      "\n",
      "Number of reviews for \"Network\" items: 13613 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "def look_keyword(data, strg):\n",
    "    content = data[data['product_title'].str.contains(strg)]\n",
    "    print(f'Number of reviews for \"{strg}\" items: {len(content)} \\n')\n",
    "    \n",
    "look_keyword(df_raw, \"Subscription\")    \n",
    "look_keyword(df_raw, \"Month\")\n",
    "look_keyword(df_raw, \"Membership\")\n",
    "look_keyword(df_raw, \"Card\")\n",
    "look_keyword(df_raw, \"Network\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 5, 4, 1, 3])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_raw['star_rating'].unique()\n",
    "#games were rated in a scale of 1 to 5 stars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All reviews date back from 2006 to 2015\n"
     ]
    }
   ],
   "source": [
    "df_raw['review_date'] = pd.to_datetime(df_raw['review_date'])\n",
    "print(f'All reviews date back from {df_raw.review_date.min().year} to {df_raw.review_date.max().year}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Droping all rows that have strings: Subscription, Month, Membership,Network on the product_title column\n",
    "df_raw_noSub = df_raw[df_raw[\"product_title\"].str.contains(\"Subscription|Month|month|Membership|Network|Credit|Season Pass|Xbox Music Pass|Virtual Currency\") == False]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Season Pass, Xbox Music Pass and Virtual Currency are some of the other kind of items on the dataset, i simply added them on the line above as i kept finding more during the process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For titles that have string 'Card' in the title, i have to be more careful since there are some game that include that on their name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Xbox Live Gift Card', 'Xbox 360 Live Points Card',\n",
       "       'Grand Theft Auto V Cash Cards', 'Hoyle Card Games 2012 AMR',\n",
       "       'Final Fantasy XIV Online: 60 Day Time Card [Online Game Code]',\n",
       "       'Hoyle Card Games  [Download]',\n",
       "       'Xbox $5 Gift Card - Xbox 360 Digital Code',\n",
       "       \"Hoyle Kid's Card Games [Download]\",\n",
       "       'Legends of Solitaire: The Lost Cards [Download]',\n",
       "       'Xbox $15 Gift Card (Call of Duty Ghosts:\\xa0Onslaught DLC) - Xbox 360 Digital Code'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def show_keyword(data, strg):\n",
    "    \"\"\"\n",
    "    func just to show examples of titles with given string,\n",
    "    to find any non-game items in the set\n",
    "    \"\"\"\n",
    "    content = data[data['product_title'].str.contains(strg)]\n",
    "    return content['product_title'].unique()[:10]\n",
    "    \n",
    "    \n",
    "show_keyword(df_raw_noSub, 'Card')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First i will drop rows where 'Gift Card' is found, then i will proceed with other common combinations of words like 'Xbox Live' and Live Points Card"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Hoyle Card Games 2012 AMR', 'Hoyle Card Games  [Download]',\n",
       "       \"Hoyle Kid's Card Games [Download]\",\n",
       "       'Legends of Solitaire: The Lost Cards [Download]',\n",
       "       'Tripeaks Solitaire Multi (Tripeaks with Multiple Card-Sets and Multiple Layouts) [Download]',\n",
       "       'Reel Deal Card Games 2011 [Download]',\n",
       "       '2,013 Card, Mahjongg & Solitaire Games [Download]',\n",
       "       'Hoyle Card Games [Mac Download]', 'Five Card Deluxe [Download]',\n",
       "       \"King's Collection: 6 Classic Card Games\"], dtype=object)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_raw_noSub2 = df_raw_noSub[df_raw_noSub[\"product_title\"].str.contains(\"Gift Card|Xbox Live|Live Points Card|Xbox Live Gift Card|Grand Theft Auto V Cash Cards|60 Day Time Card\") == False]\n",
    "\n",
    "show_keyword(df_raw_noSub2, 'Card')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seems like all items left that include \"card\" in the title are actual games\n",
    "\n",
    "<br>\n",
    "\n",
    "Lets look for DLCs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of DLCs: 212\n",
      "Total number of DLCs reviews:1698\n"
     ]
    }
   ],
   "source": [
    "DLC = df_raw_noSub2[df_raw_noSub2['product_title'].str.contains('DLC')]\n",
    "print(f\"Total number of DLCs: {DLC['product_title'].nunique()}\")\n",
    "print(f'Total number of DLC reviews:{len(DLC)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have 212 different DLCs, and 1698 reviews, an original copy of the first game is required to be able to run a DLC, I will drop these too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw_noSub_no_DLC = df_raw_noSub2[df_raw_noSub2[\"product_title\"].str.contains(\"DLC|Pack\") == False]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quantity for product id and product title still doesn't match\n",
    "\n",
    "<br>\n",
    "\n",
    "Some games include a substring next to the title, it describes the way buyers could access the game, for example:\n",
    "\n",
    "`18 Wheels of Steel American Long Haul [Download]`\n",
    "\n",
    "`18 Wheels of Steel American Long Haul [Online Game Code]`\n",
    "\n",
    "Definitely the same game, just different \"delivery\" method.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>marketplace</th>\n",
       "      <th>customer_id</th>\n",
       "      <th>review_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>product_parent</th>\n",
       "      <th>product_title</th>\n",
       "      <th>product_category</th>\n",
       "      <th>star_rating</th>\n",
       "      <th>helpful_votes</th>\n",
       "      <th>total_votes</th>\n",
       "      <th>vine</th>\n",
       "      <th>verified_purchase</th>\n",
       "      <th>review_headline</th>\n",
       "      <th>review_body</th>\n",
       "      <th>review_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>39224</th>\n",
       "      <td>US</td>\n",
       "      <td>36420328</td>\n",
       "      <td>R2LOZS1XJTWZNN</td>\n",
       "      <td>B004GHNG0E</td>\n",
       "      <td>614285704</td>\n",
       "      <td>18 Wheels of Steel American Long Haul [Download]</td>\n",
       "      <td>Digital_Video_Games</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>Four Stars</td>\n",
       "      <td>ok</td>\n",
       "      <td>2014-10-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50242</th>\n",
       "      <td>US</td>\n",
       "      <td>17845931</td>\n",
       "      <td>R2TJLHZ9X7EG83</td>\n",
       "      <td>B004GHNG0E</td>\n",
       "      <td>614285704</td>\n",
       "      <td>18 Wheels of Steel American Long Haul [Download]</td>\n",
       "      <td>Digital_Video_Games</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>Four Stars</td>\n",
       "      <td>Like driving trucks.</td>\n",
       "      <td>2014-07-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74152</th>\n",
       "      <td>US</td>\n",
       "      <td>21374226</td>\n",
       "      <td>R388BHLY4GIU5E</td>\n",
       "      <td>B00CLVZGPK</td>\n",
       "      <td>775610170</td>\n",
       "      <td>18 Wheels of Steel American Long Haul [Online ...</td>\n",
       "      <td>Digital_Video_Games</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>Doesn't work, no manufacturer support</td>\n",
       "      <td>The code I got does not work. Amazon referred ...</td>\n",
       "      <td>2013-12-29</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      marketplace  customer_id       review_id  product_id  product_parent  \\\n",
       "39224          US     36420328  R2LOZS1XJTWZNN  B004GHNG0E       614285704   \n",
       "50242          US     17845931  R2TJLHZ9X7EG83  B004GHNG0E       614285704   \n",
       "74152          US     21374226  R388BHLY4GIU5E  B00CLVZGPK       775610170   \n",
       "\n",
       "                                           product_title     product_category  \\\n",
       "39224   18 Wheels of Steel American Long Haul [Download]  Digital_Video_Games   \n",
       "50242   18 Wheels of Steel American Long Haul [Download]  Digital_Video_Games   \n",
       "74152  18 Wheels of Steel American Long Haul [Online ...  Digital_Video_Games   \n",
       "\n",
       "       star_rating  helpful_votes  total_votes vine verified_purchase  \\\n",
       "39224            4              0            0    N                 Y   \n",
       "50242            4              0            0    N                 Y   \n",
       "74152            1              1            1    N                 Y   \n",
       "\n",
       "                             review_headline  \\\n",
       "39224                             Four Stars   \n",
       "50242                             Four Stars   \n",
       "74152  Doesn't work, no manufacturer support   \n",
       "\n",
       "                                             review_body review_date  \n",
       "39224                                                 ok  2014-10-15  \n",
       "50242                               Like driving trucks.  2014-07-14  \n",
       "74152  The code I got does not work. Amazon referred ...  2013-12-29  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_raw_noSub_no_DLC[df_raw_noSub_no_DLC['product_title'].str.contains('18 Wheels of Steel American Long Haul')].head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<br>\n",
    "\n",
    "The `[Download]` edition of the game, on the second row above, has a different `product_id` than its `[Online Game Code]` edition (on the 3rd row above), it's the same game but taged with different ID, `product_parent` number is also different\n",
    "\n",
    "<br>\n",
    "\n",
    "I find it easier to modify the name than the id number, i need to group those reviews togeter, the delivery method doesnt change the software performance, so the review for a specific version is still relevant for a different one.\n",
    "\n",
    "<br>\n",
    "\n",
    "At first sight, `[Instant Access]`, `[Download]`, `[Digital Code]`, `[Game Connect]` and `[Online Game Code]` seem to be the most frequent tags at the end of the games titles, if i delete those out of the title name, i could use them for the rec system instead of the id, which was my first option"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-69-de3b04f97402>:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_raw_noSub_no_DLC['clean_title'] = df_raw_noSub_no_DLC['product_title'].str.replace(\" \\[Instant Access\\]\", \"\")\n",
      "<ipython-input-69-de3b04f97402>:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_raw_noSub_no_DLC['clean_title'] = df_raw_noSub_no_DLC['clean_title'].str.replace(\" \\[Download\\]\", \"\")\n",
      "<ipython-input-69-de3b04f97402>:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_raw_noSub_no_DLC['clean_title'] = df_raw_noSub_no_DLC['clean_title'].str.replace(\" \\[Game Connect\\]\", \"\")\n",
      "<ipython-input-69-de3b04f97402>:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_raw_noSub_no_DLC['clean_title'] = df_raw_noSub_no_DLC['clean_title'].str.replace(\" \\[Online Game Code\\]\", \"\")\n",
      "<ipython-input-69-de3b04f97402>:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_raw_noSub_no_DLC['clean_title'] = df_raw_noSub_no_DLC['clean_title'].str.replace(\" \\[Digital Code\\]\", \"\")\n"
     ]
    }
   ],
   "source": [
    "df_raw_noSub_no_DLC['clean_title'] = df_raw_noSub_no_DLC['product_title'].str.replace(\" \\[Instant Access\\]\", \"\")\n",
    "df_raw_noSub_no_DLC['clean_title'] = df_raw_noSub_no_DLC['clean_title'].str.replace(\" \\[Download\\]\", \"\")\n",
    "df_raw_noSub_no_DLC['clean_title'] = df_raw_noSub_no_DLC['clean_title'].str.replace(\" \\[Game Connect\\]\", \"\")\n",
    "df_raw_noSub_no_DLC['clean_title'] = df_raw_noSub_no_DLC['clean_title'].str.replace(\" \\[Online Game Code\\]\", \"\")\n",
    "df_raw_noSub_no_DLC['clean_title'] = df_raw_noSub_no_DLC['clean_title'].str.replace(\" \\[Digital Code\\]\", \"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first title (on index 0) has 'Xbox One Digital Code' in its name, will check if there are more games with this same substring, or even for a different platform other than xbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-67-00b8bc71ca71>:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_raw_noSub_no_DLC['clean_title'] = df_raw_noSub_no_DLC['clean_title'].str.replace(\" - Xbox One Digital Code\", \"\")\n",
      "<ipython-input-67-00b8bc71ca71>:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_raw_noSub_no_DLC['clean_title'] = df_raw_noSub_no_DLC['clean_title'].str.replace(\" - Xbox 360 Digital Code\", \"\")\n"
     ]
    }
   ],
   "source": [
    "#below i deleted the susbstring using same method as before\n",
    "df_raw_noSub_no_DLC['clean_title'] = df_raw_noSub_no_DLC['clean_title'].str.replace(\" - Xbox One Digital Code\", \"\")\n",
    "\n",
    "#found it for the 360 console too\n",
    "df_raw_noSub_no_DLC['clean_title'] = df_raw_noSub_no_DLC['clean_title'].str.replace(\" - Xbox 360 Digital Code\", \"\")\n",
    "\n",
    "#found ' - PS4', ' - PS3', ' - PS Vita / PS4 / PS3', ' - PS Vita'\n",
    "df_raw_noSub_no_DLC['clean_title'] = df_raw_noSub_no_DLC['clean_title'].str.replace(\" - PS Vita / PS4 / PS3\", \"\")\n",
    "df_raw_noSub_no_DLC['clean_title'] = df_raw_noSub_no_DLC['clean_title'].str.replace(\" - PS Vita\", \"\")\n",
    "df_raw_noSub_no_DLC['clean_title'] = df_raw_noSub_no_DLC['clean_title'].str.replace(\" - PS3\", \"\")\n",
    "df_raw_noSub_no_DLC['clean_title'] = df_raw_noSub_no_DLC['clean_title'].str.replace(\" - PS4\", \"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of customers in dataset:76941\n",
      "Total number of games in dataset:6001\n"
     ]
    }
   ],
   "source": [
    "#New frame with cleaned data and only columns needed\n",
    "Df_clean = df_raw_noSub_no_DLC[['customer_id', 'clean_title', 'star_rating']]\n",
    "#reseting index\n",
    "Df_clean.reset_index(drop=True, inplace=True)\n",
    "\n",
    "print(f'Total number of customers in dataset:{Df_clean.customer_id.nunique()}')\n",
    "print(f'Total number of games in dataset:{Df_clean.clean_title.nunique()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of customers in dataset:11133\n",
      "Total number of games in dataset:4756\n",
      "Total number of ratings in dataset:35362\n"
     ]
    }
   ],
   "source": [
    "# Subsetting to remove the customers with less than 2 reviews\n",
    "Df_clean_subset = Df_clean[Df_clean['customer_id'].map(Df_clean['customer_id'].value_counts()) > 1]\n",
    "\n",
    "print(f'Total number of customers in dataset:{Df_clean_subset.customer_id.nunique()}')\n",
    "print(f'Total number of games in dataset:{Df_clean_subset.clean_title.nunique()}')\n",
    "print((f'Total number of ratings in dataset:{len(Df_clean_subset)}'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving as new file\n",
    "Df_clean_subset.to_csv('./data/GameRatings.csv', index=False)\n",
    "Ratings = pd.read_csv('./data/GameRatings.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing for modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise import Dataset, Reader\n",
    "from surprise.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = Reader(line_format='user item rating',\n",
    "                sep=',', \n",
    "                rating_scale=(1, 5))\n",
    "\n",
    "data = Dataset.load_from_df(Ratings[['customer_id', 'clean_title', 'star_rating']], reader=reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of users:  10829\n",
      "Number of items:  4424\n",
      "Number of ratings:  28289\n"
     ]
    }
   ],
   "source": [
    "trainset, testset = train_test_split(data, test_size=0.2)\n",
    "\n",
    "print('Number of users: ', trainset.n_users)\n",
    "print('Number of items: ', trainset.n_items)\n",
    "print('Number of ratings: ', trainset.n_ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for looking back into de meaning of each id\n",
    "trainset_iids = list(trainset.all_items())\n",
    "iid_converter = lambda x: trainset.to_raw_iid(x)\n",
    "trainset_raw_iids = list(map(iid_converter, trainset_iids))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will be using scikit-surprise models to built the recomender system, Using collaborative-filtering, i will first train a model with a memory-based method; later i will explore and perform gridsearch with a model-based approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 1.3764\n",
      "MAE:  1.0816\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.0815825703187985"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import surprise\n",
    "from surprise.prediction_algorithms import *\n",
    "from surprise import accuracy\n",
    "\n",
    "KNNbaseline_model = KNNBaseline()\n",
    "KNNbaseline_model.fit(trainset)\n",
    "\n",
    "#getting predictions using testset\n",
    "KNNb_predictions = KNNbaseline_model.test(testset)\n",
    "\n",
    "# Root Mean Square Error and Mean Absolute Error\n",
    "accuracy.rmse(KNNb_predictions)\n",
    "accuracy.mae(KNNb_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Cross validation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating RMSE of algorithm KNNBaseline on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    1.3752  1.3637  1.4010  1.3841  1.3857  1.3819  0.0123  \n",
      "RMSE (trainset)   0.4169  0.4172  0.4159  0.4160  0.4163  0.4165  0.0005  \n",
      "Fit time          7.00    7.09    7.00    6.78    6.75    6.92    0.14    \n",
      "Test time         0.26    0.26    0.26    0.27    0.27    0.26    0.01    \n"
     ]
    }
   ],
   "source": [
    "from surprise.model_selection import cross_validate\n",
    "\n",
    "KNNb_cv = cross_validate(algo = KNNbaseline_model, \n",
    "                         data = data, \n",
    "                         measures=['RMSE'], \n",
    "                         cv=5, \n",
    "                         n_jobs= -2,\n",
    "                         return_train_measures=True, \n",
    "                        verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.381937964988524"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "KNNb_cv['test_rmse'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVD Simple model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 1.3008\n",
      "MAE:  1.0567\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.056711892024892"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from surprise.prediction_algorithms import SVD\n",
    "\n",
    "SVD_model = SVD(random_state=1)\n",
    "SVD_model.fit(trainset)\n",
    "\n",
    "#getting predictions using testset\n",
    "SVD_predictions = SVD_model.test(testset)\n",
    "\n",
    "# Root Mean Square Error and Mean Absolute Error\n",
    "accuracy.rmse(SVD_predictions)\n",
    "accuracy.mae(SVD_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RMSE slightly  lower than KNN baseline,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Cross validation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating RMSE of algorithm SVD on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    1.3064  1.2975  1.3307  1.2826  1.3016  1.3038  0.0156  \n",
      "RMSE (trainset)   0.8788  0.8788  0.8712  0.8815  0.8765  0.8774  0.0035  \n",
      "Fit time          1.37    1.35    1.38    1.54    1.37    1.40    0.07    \n",
      "Test time         0.03    0.03    0.03    0.03    0.03    0.03    0.00    \n"
     ]
    }
   ],
   "source": [
    "SVD_cv = cross_validate(algo = SVD_model, \n",
    "                        data = data, \n",
    "                        measures=['RMSE'], \n",
    "                        cv=5, \n",
    "                        n_jobs=-2, \n",
    "                        verbose=True, \n",
    "                        return_train_measures=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.3037753163631471"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SVD_cv['test_rmse'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVD Gridsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-2)]: Using backend LokyBackend with 7 concurrent workers.\n",
      "[Parallel(n_jobs=-2)]: Done   4 tasks      | elapsed:    1.2s\n",
      "[Parallel(n_jobs=-2)]: Done  58 tasks      | elapsed:    5.4s\n",
      "[Parallel(n_jobs=-2)]: Done 148 tasks      | elapsed:   22.3s\n",
      "[Parallel(n_jobs=-2)]: Done 274 tasks      | elapsed:   45.2s\n",
      "[Parallel(n_jobs=-2)]: Done 436 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-2)]: Done 540 out of 540 | elapsed:  2.2min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'rmse': {'n_factors': 100,\n",
       "  'n_epochs': 20,\n",
       "  'lr_all': 0.05,\n",
       "  'reg_all': 0.1,\n",
       "  'biased': True}}"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from surprise.model_selection import GridSearchCV\n",
    "\n",
    "# Setting hyperparameters around default values\n",
    "SVD_grid = {'n_factors':[50, 100, 120],\n",
    "           'n_epochs':[10, 20, 40],\n",
    "           'lr_all':[0.002, 0.005, 0.05],\n",
    "           'reg_all':[0.02, 0.1], \n",
    "           'biased':[True, False]}\n",
    "\n",
    "SVD_gs = GridSearchCV(algo_class = SVD, \n",
    "                      param_grid = SVD_grid, \n",
    "                      measures=['rmse'], \n",
    "                      n_jobs = -2, \n",
    "                      joblib_verbose = 5)\n",
    "\n",
    "SVD_gs.fit(data)\n",
    "SVD_gs.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 1.2748\n",
      "MAE:  1.0134\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.0133878649254648"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using best parameters in new model and only fiting train set\n",
    "svd_1 = SVD(lr_all=0.05, reg_all= .01)\n",
    "\n",
    "svd_1.fit(trainset)\n",
    "\n",
    "#getting predictions using testset\n",
    "SVD_pred_1 = svd_1.test(testset)\n",
    "\n",
    "# Root Mean Square Error and Mean Absolute Error\n",
    "accuracy.rmse(SVD_pred_1)\n",
    "accuracy.mae(SVD_pred_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gridsearch did improve RMSE from baseline model, biased, n_factors and n_epochs stayed in default values while lr_all and reg_all where pick with hightes value given."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVD Gridsearch 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-2)]: Using backend LokyBackend with 7 concurrent workers.\n",
      "[Parallel(n_jobs=-2)]: Done   4 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=-2)]: Done  58 tasks      | elapsed:    5.3s\n",
      "[Parallel(n_jobs=-2)]: Done 148 tasks      | elapsed:   21.2s\n",
      "[Parallel(n_jobs=-2)]: Done 274 tasks      | elapsed:   44.5s\n",
      "[Parallel(n_jobs=-2)]: Done 436 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-2)]: Done 540 out of 540 | elapsed:  2.2min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'rmse': {'n_factors': 100, 'n_epochs': 10, 'lr_all': 0.05, 'reg_all': 0.3}}"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Setting hyperparameters around default values\n",
    "SVD_grid_2 = {'n_factors':[50, 100, 120],\n",
    "           'n_epochs':[10, 20, 40],\n",
    "           'lr_all':[0.005, 0.05, 0.08],\n",
    "           'reg_all':[0.02, 0.1, 0.3, 0.5]}\n",
    "\n",
    "SVD_gs_2 = GridSearchCV(algo_class = SVD, \n",
    "                      param_grid = SVD_grid_2, \n",
    "                      measures=['rmse'], \n",
    "                      n_jobs = -2, \n",
    "                      joblib_verbose = 5)\n",
    "\n",
    "SVD_gs_2.fit(data)\n",
    "SVD_gs_2.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 1.2591\n",
      "MAE:  1.0114\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.011404739566474"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using best parameters in new model and only fiting train set\n",
    "svd_2 = SVD(n_epochs= 10, lr_all=0.05, reg_all= 0.3)\n",
    "\n",
    "svd_2.fit(trainset)\n",
    "\n",
    "#getting predictions using testset\n",
    "SVD_pred_2 = svd_2.test(testset)\n",
    "\n",
    "# Root Mean Square Error and Mean Absolute Error\n",
    "accuracy.rmse(SVD_pred_2)\n",
    "accuracy.mae(SVD_pred_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVD Gridsearch 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-2)]: Using backend LokyBackend with 7 concurrent workers.\n",
      "[Parallel(n_jobs=-2)]: Done   4 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=-2)]: Done  58 tasks      | elapsed:    4.9s\n",
      "[Parallel(n_jobs=-2)]: Done 148 tasks      | elapsed:   15.5s\n",
      "[Parallel(n_jobs=-2)]: Done 274 tasks      | elapsed:   31.1s\n",
      "[Parallel(n_jobs=-2)]: Done 405 out of 405 | elapsed:   49.7s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'rmse': {'n_factors': 80, 'n_epochs': 10, 'lr_all': 0.05, 'reg_all': 0.3}}"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Setting hyperparameters around default values\n",
    "SVD_grid_3 = {'n_factors':[80, 100, 120],\n",
    "           'n_epochs':[5, 10, 15],\n",
    "           'lr_all':[0.01, 0.05, 0.08],\n",
    "           'reg_all':[0.1, 0.3, 0.5]}\n",
    "\n",
    "SVD_gs_3 = GridSearchCV(algo_class = SVD, \n",
    "                      param_grid = SVD_grid_3, \n",
    "                      measures=['rmse'], \n",
    "                      n_jobs = -2, \n",
    "                      joblib_verbose = 5)\n",
    "\n",
    "SVD_gs_3.fit(data)\n",
    "SVD_gs_3.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 1.2561\n",
      "MAE:  1.0068\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.0067608879084728"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using best parameters in new model and only fiting train set\n",
    "svd_3 = SVD(n_factors=80, n_epochs= 10, lr_all=0.05, reg_all= 0.3)\n",
    "\n",
    "svd_3.fit(trainset)\n",
    "\n",
    "#getting predictions using testset\n",
    "SVD_pred_3 = svd_3.test(testset)\n",
    "\n",
    "# Root Mean Square Error and Mean Absolute Error\n",
    "accuracy.rmse(SVD_pred_3)\n",
    "accuracy.mae(SVD_pred_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decrease on RMSE from previous gridsearch was minimal, will move on and SVD++"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVD++"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise import Dataset, SVD\n",
    "from surprise.model_selection import cross_validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise.prediction_algorithms import SVD\n",
    "from surprise.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "!ls data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import gzip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "vec_tfidf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def parse(path):\n",
    "  g = gzip.open(path, 'rb')\n",
    "  for l in g:\n",
    "    yield eval(l)\n",
    "\n",
    "def getDF(path):\n",
    "  i = 0\n",
    "  df = {}\n",
    "  for d in parse(path):\n",
    "    df[i] = d\n",
    "    i += 1\n",
    "  return pd.DataFrame.from_dict(df, orient='index')\n",
    "\n",
    "meta_df = getDF('./data/meta_Video_Games.json.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (learn-env)",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
