{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![cover](./images/cover.jpg) **Author: Juan Acosta**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Business understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In recent years, the video game industry has seen a significant shift towards digital sales, with a majority of global revenue coming from digital channels. In 2022, it is estimated that over 75% of global video game revenue was generated through digital sales([source](https://www.pushsquare.com/news/2022/07/nearly-80percent-of-all-ps5-ps4-games-are-bought-digitally)), indicating a strong trend towards online purchasing and digital distribution of games. This shift towards digital sales is likely driven by a number of factors, including the increasing prevalence of high-speed internet and the convenience of being able to purchase and download games directly to a device without the need for physical copies. As the video game industry continues to evolve and technology advances, it is likely that digital sales will continue to grow in importance.\n",
    "\n",
    "Video game recommendation systems are useful because they can help players discover new games that they might enjoy based on their past behavior and preferences. In a market where there are thousands of available games, it can be overwhelming for players to go through all of the options and find something that suits their interests. A recommendation system can help narrow down the options and suggest games that are more likely to be of interest to the user. A potential issue with recommender systems on official platform stores for digital games is that they may prioritize promoting newer games that are more profitable for the store, potentially at the expense of recommending older but high-quality games. This can lead to customers missing out on discovering older games that they might enjoy. It is important to be aware of this potential bias and to consider using other sources of recommendations in addition to the official platform store's."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To build a recommendation system, I used a dataset containing reviews from over 112,000 customers on more than 7,000 different game titles, for a total of over 140,000 reviews. Using the pandas library in Python, I began by performing exploratory data analysis (EDA) on the dataset, focusing on the columns that would be used as input for the recommendation algorithm. This process involved cleaning and preprocessing the data, identifying any patterns and selecting appropriate features for the model.\n",
    "\n",
    "Amazon reviews dataset on kaggle [here](https://www.kaggle.com/datasets/cynthiarempel/amazon-us-customer-reviews-dataset?select=amazon_reviews_us_Digital_Video_Games_v1_00.tsv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 144724 entries, 0 to 144723\n",
      "Data columns (total 15 columns):\n",
      " #   Column             Non-Null Count   Dtype \n",
      "---  ------             --------------   ----- \n",
      " 0   marketplace        144724 non-null  object\n",
      " 1   customer_id        144724 non-null  int64 \n",
      " 2   review_id          144724 non-null  object\n",
      " 3   product_id         144724 non-null  object\n",
      " 4   product_parent     144724 non-null  int64 \n",
      " 5   product_title      144724 non-null  object\n",
      " 6   product_category   144724 non-null  object\n",
      " 7   star_rating        144724 non-null  int64 \n",
      " 8   helpful_votes      144724 non-null  int64 \n",
      " 9   total_votes        144724 non-null  int64 \n",
      " 10  vine               144724 non-null  object\n",
      " 11  verified_purchase  144724 non-null  object\n",
      " 12  review_headline    144722 non-null  object\n",
      " 13  review_body        144722 non-null  object\n",
      " 14  review_date        144721 non-null  object\n",
      "dtypes: int64(5), object(10)\n",
      "memory usage: 16.6+ MB\n"
     ]
    }
   ],
   "source": [
    "df_raw = pd.read_csv('./data/Digital_Video_Games.tsv', sep='\\t', header=0, error_bad_lines=False)\n",
    "df_raw.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "marketplace          0\n",
       "customer_id          0\n",
       "review_id            0\n",
       "product_id           0\n",
       "product_parent       0\n",
       "product_title        0\n",
       "product_category     0\n",
       "star_rating          0\n",
       "helpful_votes        0\n",
       "total_votes          0\n",
       "vine                 0\n",
       "verified_purchase    0\n",
       "review_headline      2\n",
       "review_body          2\n",
       "review_date          3\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_raw.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Columns\n",
    "- **marketplace**: 2 letter country code of the marketplace where the review was written.\n",
    "- **customer_id**: Random identifier that can be used to aggregate reviews written by a single author.\n",
    "- **review_id**: The unique ID of the review.\n",
    "- **productid**: The unique Product ID the review pertains to. In the multilingual dataset the reviews for the same product in different countries can be grouped by the same productid.\n",
    "- **product_parent**: Random identifier that can be used to aggregate reviews for the same product.\n",
    "- **product_title**: Title of the product.\n",
    "- **product_category**: Broad product category that can be used to group reviews (also used to group the dataset into coherent parts).\n",
    "- **star_rating**: The 1-5 star rating of the review.\n",
    "- **helpful_votes**: Number of helpful votes.\n",
    "- **total_votes**: Number of total votes the review received.\n",
    "- **vine**: Review was written as part of the Vine program.\n",
    "- **verified_purchase**: The review is on a verified purchase.\n",
    "- **review_headline**: The title of the review.\n",
    "- **review_body**: The review text.\n",
    "- **review_date**: The date the review was written."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['US'], dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_raw['marketplace'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All reviews in dataset are from US customers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "112891"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_raw['customer_id'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "112891 different customers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "144724"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_raw['review_id'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seems like there are no duplicate reviews in the set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7939"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_raw['product_id'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7939 different products, but not all video games, found \"Playstation Plus Subscription\" in row 3, so all digitally sold products related video games, like subscriptions, seem to be included in the data set, will further look for other kind of product other than games and drop those."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7755"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_raw['product_parent'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **product_parent**: Random identifier that can be used to aggregate reviews for the same product.\n",
    "\n",
    "seems like just another id but we have about 200 less data points in this column than product id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6946"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_raw['product_title'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If i have 6946 different titles, i would expect the same amount of product_id, wonder if by droping everything that is not a game, like substriptions, would fix this discrepancy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Playstation Plus Subscription'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_raw.iloc[3]['product_title']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It doesnt specify if the subscription is for 1, 3 or 12 months\n",
    "\n",
    "<br>\n",
    "\n",
    "Below i used key words to look for any products that is not a game\n",
    "e.g\n",
    "- Subscription\n",
    "- Month\n",
    "- Membership\n",
    "- Card\n",
    "- Network\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of reviews for \"Subscription\" items: 12137 \n",
      "\n",
      "Number of reviews for \"Month\" items: 630 \n",
      "\n",
      "Number of reviews for \"Membership\" items: 275 \n",
      "\n",
      "Number of reviews for \"Card\" items: 21173 \n",
      "\n",
      "Number of reviews for \"Network\" items: 13613 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "def look_keyword(data, strg):\n",
    "    content = data[data['product_title'].str.contains(strg)]\n",
    "    print(f'Number of reviews for \"{strg}\" items: {len(content)} \\n')\n",
    "    \n",
    "look_keyword(df_raw, \"Subscription\")    \n",
    "look_keyword(df_raw, \"Month\")\n",
    "look_keyword(df_raw, \"Membership\")\n",
    "look_keyword(df_raw, \"Card\")\n",
    "look_keyword(df_raw, \"Network\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 5, 4, 1, 3])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_raw['star_rating'].unique()\n",
    "#games were rated in a scale of 1 to 5 stars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All reviews date back from 2006 to 2015\n"
     ]
    }
   ],
   "source": [
    "df_raw['review_date'] = pd.to_datetime(df_raw['review_date'])\n",
    "print(f'All reviews date back from {df_raw.review_date.min().year} to {df_raw.review_date.max().year}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Droping all rows that have strings: Subscription, Month, Membership,Network on the product_title column\n",
    "df_raw_noSub = df_raw[df_raw[\"product_title\"].str.contains(\"Subscription|Month|month|Membership|Network|Credit|Season Pass|Xbox Music Pass|Virtual Currency\") == False]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Season Pass, Xbox Music Pass and Virtual Currency are some of the other kind of items on the dataset, i simply added them on the line above as i kept finding more during the process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For titles that have string 'Card' in the title, i have to be more careful since there are some game that include that on their name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Xbox Live Gift Card', 'Xbox 360 Live Points Card',\n",
       "       'Grand Theft Auto V Cash Cards', 'Hoyle Card Games 2012 AMR',\n",
       "       'Final Fantasy XIV Online: 60 Day Time Card [Online Game Code]',\n",
       "       'Hoyle Card Games  [Download]',\n",
       "       'Xbox $5 Gift Card - Xbox 360 Digital Code',\n",
       "       \"Hoyle Kid's Card Games [Download]\",\n",
       "       'Legends of Solitaire: The Lost Cards [Download]',\n",
       "       'Xbox $15 Gift Card (Call of Duty Ghosts:\\xa0Onslaught DLC) - Xbox 360 Digital Code'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def show_keyword(data, strg):\n",
    "    \"\"\"\n",
    "    func just to show examples of titles with given string,\n",
    "    to find any non-game items in the set\n",
    "    \"\"\"\n",
    "    content = data[data['product_title'].str.contains(strg)]\n",
    "    return content['product_title'].unique()[:10]\n",
    "    \n",
    "    \n",
    "show_keyword(df_raw_noSub, 'Card')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First i will drop rows where 'Gift Card' is found, then i will proceed with other common combinations of words like 'Xbox Live' and Live Points Card"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Hoyle Card Games 2012 AMR', 'Hoyle Card Games  [Download]',\n",
       "       \"Hoyle Kid's Card Games [Download]\",\n",
       "       'Legends of Solitaire: The Lost Cards [Download]',\n",
       "       'Tripeaks Solitaire Multi (Tripeaks with Multiple Card-Sets and Multiple Layouts) [Download]',\n",
       "       'Reel Deal Card Games 2011 [Download]',\n",
       "       '2,013 Card, Mahjongg & Solitaire Games [Download]',\n",
       "       'Hoyle Card Games [Mac Download]', 'Five Card Deluxe [Download]',\n",
       "       \"King's Collection: 6 Classic Card Games\"], dtype=object)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_raw_noSub2 = df_raw_noSub[df_raw_noSub[\"product_title\"].str.contains(\"Gift Card|Xbox Live|Live Points Card|Xbox Live Gift Card|Grand Theft Auto V Cash Cards|60 Day Time Card\") == False]\n",
    "\n",
    "show_keyword(df_raw_noSub2, 'Card')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seems like all items left that include \"card\" in the title are actual games\n",
    "\n",
    "<br>\n",
    "\n",
    "Lets look for DLCs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of DLCs: 212\n",
      "Total number of DLC reviews:1698\n"
     ]
    }
   ],
   "source": [
    "DLC = df_raw_noSub2[df_raw_noSub2['product_title'].str.contains('DLC')]\n",
    "print(f\"Total number of DLCs: {DLC['product_title'].nunique()}\")\n",
    "print(f'Total number of DLC reviews:{len(DLC)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have 212 different DLCs, and 1698 reviews, an original copy of the first game is required to be able to run a DLC, I will drop these too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw_noSub_no_DLC = df_raw_noSub2[df_raw_noSub2[\"product_title\"].str.contains(\"DLC|Pack\") == False]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quantity for product id and product title still doesn't match\n",
    "\n",
    "<br>\n",
    "\n",
    "Some games include a substring next to the title, it describes the way buyers could access the game, for example:\n",
    "\n",
    "`18 Wheels of Steel American Long Haul [Download]`\n",
    "\n",
    "`18 Wheels of Steel American Long Haul [Online Game Code]`\n",
    "\n",
    "Definitely the same game, just different \"delivery\" method.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>marketplace</th>\n",
       "      <th>customer_id</th>\n",
       "      <th>review_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>product_parent</th>\n",
       "      <th>product_title</th>\n",
       "      <th>product_category</th>\n",
       "      <th>star_rating</th>\n",
       "      <th>helpful_votes</th>\n",
       "      <th>total_votes</th>\n",
       "      <th>vine</th>\n",
       "      <th>verified_purchase</th>\n",
       "      <th>review_headline</th>\n",
       "      <th>review_body</th>\n",
       "      <th>review_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>39224</th>\n",
       "      <td>US</td>\n",
       "      <td>36420328</td>\n",
       "      <td>R2LOZS1XJTWZNN</td>\n",
       "      <td>B004GHNG0E</td>\n",
       "      <td>614285704</td>\n",
       "      <td>18 Wheels of Steel American Long Haul [Download]</td>\n",
       "      <td>Digital_Video_Games</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>Four Stars</td>\n",
       "      <td>ok</td>\n",
       "      <td>2014-10-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50242</th>\n",
       "      <td>US</td>\n",
       "      <td>17845931</td>\n",
       "      <td>R2TJLHZ9X7EG83</td>\n",
       "      <td>B004GHNG0E</td>\n",
       "      <td>614285704</td>\n",
       "      <td>18 Wheels of Steel American Long Haul [Download]</td>\n",
       "      <td>Digital_Video_Games</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>Four Stars</td>\n",
       "      <td>Like driving trucks.</td>\n",
       "      <td>2014-07-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74152</th>\n",
       "      <td>US</td>\n",
       "      <td>21374226</td>\n",
       "      <td>R388BHLY4GIU5E</td>\n",
       "      <td>B00CLVZGPK</td>\n",
       "      <td>775610170</td>\n",
       "      <td>18 Wheels of Steel American Long Haul [Online ...</td>\n",
       "      <td>Digital_Video_Games</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>Doesn't work, no manufacturer support</td>\n",
       "      <td>The code I got does not work. Amazon referred ...</td>\n",
       "      <td>2013-12-29</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      marketplace  customer_id       review_id  product_id  product_parent  \\\n",
       "39224          US     36420328  R2LOZS1XJTWZNN  B004GHNG0E       614285704   \n",
       "50242          US     17845931  R2TJLHZ9X7EG83  B004GHNG0E       614285704   \n",
       "74152          US     21374226  R388BHLY4GIU5E  B00CLVZGPK       775610170   \n",
       "\n",
       "                                           product_title     product_category  \\\n",
       "39224   18 Wheels of Steel American Long Haul [Download]  Digital_Video_Games   \n",
       "50242   18 Wheels of Steel American Long Haul [Download]  Digital_Video_Games   \n",
       "74152  18 Wheels of Steel American Long Haul [Online ...  Digital_Video_Games   \n",
       "\n",
       "       star_rating  helpful_votes  total_votes vine verified_purchase  \\\n",
       "39224            4              0            0    N                 Y   \n",
       "50242            4              0            0    N                 Y   \n",
       "74152            1              1            1    N                 Y   \n",
       "\n",
       "                             review_headline  \\\n",
       "39224                             Four Stars   \n",
       "50242                             Four Stars   \n",
       "74152  Doesn't work, no manufacturer support   \n",
       "\n",
       "                                             review_body review_date  \n",
       "39224                                                 ok  2014-10-15  \n",
       "50242                               Like driving trucks.  2014-07-14  \n",
       "74152  The code I got does not work. Amazon referred ...  2013-12-29  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_raw_noSub_no_DLC[df_raw_noSub_no_DLC['product_title'].str.contains('18 Wheels of Steel American Long Haul')].head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<br>\n",
    "\n",
    "The `[Download]` edition of the game, on the second row above, has a different `product_id` than its `[Online Game Code]` edition (on the 3rd row above), it's the same game but taged with different ID, `product_parent` number is also different\n",
    "\n",
    "<br>\n",
    "\n",
    "I find it easier to modify the name than the id number, i need to group those reviews togeter, the delivery method doesnt change the software performance, so the review for a specific version is still relevant for a different one.\n",
    "\n",
    "<br>\n",
    "\n",
    "At first sight, `[Instant Access]`, `[Download]`, `[Digital Code]`, `[Game Connect]` and `[Online Game Code]` seem to be the most frequent tags at the end of the games titles, if i delete those out of the title name, i could use them for the rec system instead of the id, which was my first option"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-20-de3b04f97402>:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_raw_noSub_no_DLC['clean_title'] = df_raw_noSub_no_DLC['product_title'].str.replace(\" \\[Instant Access\\]\", \"\")\n",
      "<ipython-input-20-de3b04f97402>:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_raw_noSub_no_DLC['clean_title'] = df_raw_noSub_no_DLC['clean_title'].str.replace(\" \\[Download\\]\", \"\")\n",
      "<ipython-input-20-de3b04f97402>:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_raw_noSub_no_DLC['clean_title'] = df_raw_noSub_no_DLC['clean_title'].str.replace(\" \\[Game Connect\\]\", \"\")\n",
      "<ipython-input-20-de3b04f97402>:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_raw_noSub_no_DLC['clean_title'] = df_raw_noSub_no_DLC['clean_title'].str.replace(\" \\[Online Game Code\\]\", \"\")\n",
      "<ipython-input-20-de3b04f97402>:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_raw_noSub_no_DLC['clean_title'] = df_raw_noSub_no_DLC['clean_title'].str.replace(\" \\[Digital Code\\]\", \"\")\n"
     ]
    }
   ],
   "source": [
    "df_raw_noSub_no_DLC['clean_title'] = df_raw_noSub_no_DLC['product_title'].str.replace(\" \\[Instant Access\\]\", \"\")\n",
    "df_raw_noSub_no_DLC['clean_title'] = df_raw_noSub_no_DLC['clean_title'].str.replace(\" \\[Download\\]\", \"\")\n",
    "df_raw_noSub_no_DLC['clean_title'] = df_raw_noSub_no_DLC['clean_title'].str.replace(\" \\[Game Connect\\]\", \"\")\n",
    "df_raw_noSub_no_DLC['clean_title'] = df_raw_noSub_no_DLC['clean_title'].str.replace(\" \\[Online Game Code\\]\", \"\")\n",
    "df_raw_noSub_no_DLC['clean_title'] = df_raw_noSub_no_DLC['clean_title'].str.replace(\" \\[Digital Code\\]\", \"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first title (on index 0) has 'Xbox One Digital Code' in its name, will check if there are more games with this same substring, or even for a different platform other than xbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-21-b0f23e8e230f>:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_raw_noSub_no_DLC['clean_title'] = df_raw_noSub_no_DLC['clean_title'].str.replace(\" - Xbox One Digital Code\", \"\")\n",
      "<ipython-input-21-b0f23e8e230f>:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_raw_noSub_no_DLC['clean_title'] = df_raw_noSub_no_DLC['clean_title'].str.replace(\" - Xbox 360 Digital Code\", \"\")\n",
      "<ipython-input-21-b0f23e8e230f>:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_raw_noSub_no_DLC['clean_title'] = df_raw_noSub_no_DLC['clean_title'].str.replace(\" - PS Vita / PS4 / PS3\", \"\")\n",
      "<ipython-input-21-b0f23e8e230f>:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_raw_noSub_no_DLC['clean_title'] = df_raw_noSub_no_DLC['clean_title'].str.replace(\" - PS Vita\", \"\")\n",
      "<ipython-input-21-b0f23e8e230f>:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_raw_noSub_no_DLC['clean_title'] = df_raw_noSub_no_DLC['clean_title'].str.replace(\" - PS3\", \"\")\n",
      "<ipython-input-21-b0f23e8e230f>:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_raw_noSub_no_DLC['clean_title'] = df_raw_noSub_no_DLC['clean_title'].str.replace(\" - PS4\", \"\")\n"
     ]
    }
   ],
   "source": [
    "#below i deleted the susbstring using same method as before\n",
    "df_raw_noSub_no_DLC['clean_title'] = df_raw_noSub_no_DLC['clean_title'].str.replace(\" - Xbox One Digital Code\", \"\")\n",
    "\n",
    "#found it for the 360 console too\n",
    "df_raw_noSub_no_DLC['clean_title'] = df_raw_noSub_no_DLC['clean_title'].str.replace(\" - Xbox 360 Digital Code\", \"\")\n",
    "\n",
    "#found ' - PS4', ' - PS3', ' - PS Vita / PS4 / PS3', ' - PS Vita'\n",
    "df_raw_noSub_no_DLC['clean_title'] = df_raw_noSub_no_DLC['clean_title'].str.replace(\" - PS Vita / PS4 / PS3\", \"\")\n",
    "df_raw_noSub_no_DLC['clean_title'] = df_raw_noSub_no_DLC['clean_title'].str.replace(\" - PS Vita\", \"\")\n",
    "df_raw_noSub_no_DLC['clean_title'] = df_raw_noSub_no_DLC['clean_title'].str.replace(\" - PS3\", \"\")\n",
    "df_raw_noSub_no_DLC['clean_title'] = df_raw_noSub_no_DLC['clean_title'].str.replace(\" - PS4\", \"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of customers in dataset:76853\n",
      "Total number of games in dataset:6000\n"
     ]
    }
   ],
   "source": [
    "#New frame with cleaned data and only columns needed\n",
    "Df_clean = df_raw_noSub_no_DLC[['customer_id', 'clean_title', 'star_rating']]\n",
    "#reseting index\n",
    "Df_clean.reset_index(drop=True, inplace=True)\n",
    "\n",
    "print(f'Total number of customers in dataset:{Df_clean.customer_id.nunique()}')\n",
    "print(f'Total number of games in dataset:{Df_clean.clean_title.nunique()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of customers in dataset:1375\n",
      "Total number of games in dataset:3383\n",
      "Total number of reviews/ratings in dataset:12200\n"
     ]
    }
   ],
   "source": [
    "# Subsetting to remove the customers with less than 5 reviews\n",
    "Df_clean_subset = Df_clean[Df_clean['customer_id'].map(Df_clean['customer_id'].value_counts()) >= 5]\n",
    "\n",
    "print(f'Total number of customers in dataset:{Df_clean_subset.customer_id.nunique()}')\n",
    "print(f'Total number of games in dataset:{Df_clean_subset.clean_title.nunique()}')\n",
    "print((f'Total number of reviews/ratings in dataset:{len(Df_clean_subset)}'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving as new file\n",
    "Df_clean_subset.to_csv('./data/GameRatings.csv', index=False)\n",
    "Ratings = pd.read_csv('./data/GameRatings.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing for modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of users:  1375\n",
      "Number of items:  3043\n",
      "Number of ratings:  9760\n"
     ]
    }
   ],
   "source": [
    "from surprise import Dataset, Reader\n",
    "from surprise.model_selection import train_test_split\n",
    "\n",
    "# Creating reader object and loading data in new format\n",
    "reader = Reader(line_format='user item rating',\n",
    "                sep=',', \n",
    "                rating_scale=(1, 5))\n",
    "\n",
    "data = Dataset.load_from_df(Ratings[['customer_id', 'clean_title', 'star_rating']], reader=reader)\n",
    "\n",
    "# split data into train and test sets\n",
    "trainset, testset = train_test_split(data, test_size=0.2)\n",
    "\n",
    "print('Number of users: ', trainset.n_users)\n",
    "print('Number of items: ', trainset.n_items)\n",
    "print('Number of ratings: ', trainset.n_ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for looking back into de meaning of each id\n",
    "trainset_iids = list(trainset.all_items())\n",
    "iid_converter = lambda x: trainset.to_raw_iid(x)\n",
    "trainset_raw_iids = list(map(iid_converter, trainset_iids))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To build the recommendation system, I am using scikit-surprise library in Python, which includes a range of algorithms and tools for building and evaluating recommendation models. Specifically, I will be using collaborative filtering techniques to make recommendations based on the similarity of users and items.\n",
    "\n",
    "As a first step, I will train a model using a memory-based method, which utilizes the entire dataset to make predictions. After building the initial model, I will then explore the use of a model-based approach, which involves using machine learning algorithms to learn the underlying relationships in the data and make predictions. To tune the model and find the best set of hyperparameters, I will use grid search to try different combinations of parameters and evaluate their performance using root mean squared error.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise.prediction_algorithms import *\n",
    "from surprise import accuracy\n",
    "from surprise.model_selection import cross_validate, GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 1.3060\n",
      "MAE:  0.9965\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9965072695389573"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "KNNbaseline_model = KNNBaseline()\n",
    "KNNbaseline_model.fit(trainset)\n",
    "\n",
    "#getting predictions using testset\n",
    "KNNb_predictions = KNNbaseline_model.test(testset)\n",
    "\n",
    "# Root Mean Square Error and Mean Absolute Error\n",
    "accuracy.rmse(KNNb_predictions)\n",
    "accuracy.mae(KNNb_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Cross validation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating RMSE of algorithm KNNBaseline on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    1.2991  1.3039  1.2801  1.2995  1.3050  1.2975  0.0090  \n",
      "RMSE (trainset)   0.4071  0.4020  0.4051  0.4058  0.4044  0.4049  0.0017  \n",
      "Fit time          0.05    0.05    0.06    0.06    0.06    0.06    0.00    \n",
      "Test time         0.03    0.03    0.03    0.03    0.03    0.03    0.00    \n"
     ]
    }
   ],
   "source": [
    "KNNb_cv = cross_validate(algo = KNNbaseline_model, \n",
    "                         data = data, \n",
    "                         measures=['RMSE'], \n",
    "                         cv=5, \n",
    "                         n_jobs= -2,\n",
    "                         return_train_measures=True, \n",
    "                        verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 1.7023\n",
      "MAE:  1.3312\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.3312096630600092"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate and fit model\n",
    "baseline = NormalPredictor()\n",
    "baseline.fit(trainset)\n",
    "\n",
    "# Return test predictions for model fit on trainset\n",
    "base_pred = baseline.test(testset)\n",
    "\n",
    "# Save RMSE score to variable\n",
    "accuracy.rmse(base_pred)\n",
    "accuracy.mae(base_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVD Simple model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 1.1973\n",
      "MAE:  0.9587\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.958726958002533"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SVD_model = SVD(random_state=1)\n",
    "SVD_model.fit(trainset)\n",
    "\n",
    "#getting predictions using testset\n",
    "SVD_predictions = SVD_model.test(testset)\n",
    "\n",
    "# Root Mean Square Error and Mean Absolute Error\n",
    "accuracy.rmse(SVD_predictions)\n",
    "accuracy.mae(SVD_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RMSE  lower than KNN and baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Cross validation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating RMSE of algorithm SVD on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    1.2009  1.1820  1.1814  1.1911  1.1803  1.1871  0.0079  \n",
      "RMSE (trainset)   0.8149  0.8194  0.8222  0.8214  0.8248  0.8205  0.0033  \n",
      "Fit time          0.46    0.53    0.46    0.46    0.45    0.47    0.03    \n",
      "Test time         0.01    0.01    0.01    0.01    0.01    0.01    0.00    \n"
     ]
    }
   ],
   "source": [
    "SVD_cv = cross_validate(algo = SVD_model, \n",
    "                        data = data, \n",
    "                        measures=['RMSE'], \n",
    "                        cv=5, \n",
    "                        n_jobs=-2, \n",
    "                        verbose=True, \n",
    "                        return_train_measures=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVD Gridsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-2)]: Using backend LokyBackend with 7 concurrent workers.\n",
      "[Parallel(n_jobs=-2)]: Done   4 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=-2)]: Done 102 tasks      | elapsed:    3.9s\n",
      "[Parallel(n_jobs=-2)]: Done 225 tasks      | elapsed:   11.8s\n",
      "[Parallel(n_jobs=-2)]: Done 351 tasks      | elapsed:   25.1s\n",
      "[Parallel(n_jobs=-2)]: Done 513 tasks      | elapsed:   40.4s\n",
      "[Parallel(n_jobs=-2)]: Done 540 out of 540 | elapsed:   45.1s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'n_factors': 50,\n",
       " 'n_epochs': 40,\n",
       " 'lr_all': 0.005,\n",
       " 'reg_all': 0.1,\n",
       " 'biased': True,\n",
       " 'random_state': 1}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Setting hyperparameters around default values\n",
    "SVD_grid = {'n_factors':[50, 100, 120],\n",
    "           'n_epochs':[10, 20, 40],\n",
    "           'lr_all':[0.002, 0.005, 0.05],\n",
    "           'reg_all':[0.02, 0.1], \n",
    "           'biased':[True, False], \n",
    "           'random_state':[1]}\n",
    "\n",
    "SVD_gs = GridSearchCV(algo_class = SVD, \n",
    "                      param_grid = SVD_grid, \n",
    "                      measures=['rmse'], \n",
    "                      n_jobs = -2, \n",
    "                      joblib_verbose = 5)\n",
    "\n",
    "SVD_gs.fit(data)\n",
    "SVD_gs.best_params['rmse']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 1.1755\n",
      "MAE:  0.9263\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9263225202879481"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using best parameters in new model and only fiting train set\n",
    "svd_1 = SVD(n_factors=50, n_epochs=40, lr_all=0.005, reg_all= .1, random_state=1)\n",
    "\n",
    "svd_1.fit(trainset)\n",
    "\n",
    "#getting predictions using testset\n",
    "SVD_pred_1 = svd_1.test(testset)\n",
    "\n",
    "# Root Mean Square Error and Mean Absolute Error\n",
    "accuracy.rmse(SVD_pred_1)\n",
    "accuracy.mae(SVD_pred_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gridsearch did improve RMSE from baseline model, will set grid arround hyperparameters given on the last search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVD Gridsearch 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-2)]: Using backend LokyBackend with 7 concurrent workers.\n",
      "[Parallel(n_jobs=-2)]: Done   4 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=-2)]: Done  58 tasks      | elapsed:    3.2s\n",
      "[Parallel(n_jobs=-2)]: Done 148 tasks      | elapsed:    8.3s\n",
      "[Parallel(n_jobs=-2)]: Done 274 tasks      | elapsed:   17.1s\n",
      "[Parallel(n_jobs=-2)]: Done 436 tasks      | elapsed:   30.0s\n",
      "[Parallel(n_jobs=-2)]: Done 634 tasks      | elapsed:   43.5s\n",
      "[Parallel(n_jobs=-2)]: Done 868 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-2)]: Done 1138 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-2)]: Done 1444 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=-2)]: Done 1786 tasks      | elapsed:  2.6min\n",
      "[Parallel(n_jobs=-2)]: Done 2164 tasks      | elapsed:  3.3min\n",
      "[Parallel(n_jobs=-2)]: Done 2400 out of 2400 | elapsed:  3.8min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'n_factors': 30,\n",
       " 'n_epochs': 50,\n",
       " 'lr_all': 0.005,\n",
       " 'reg_all': 0.2,\n",
       " 'random_state': 1}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Setting hyperparameters around default values\n",
    "SVD_grid_2 = {'n_factors':[30, 40, 50, 60, 70], \n",
    "              'n_epochs':[30, 35, 40, 45, 50, 55], \n",
    "              'lr_all':[0.001, 0.003, 0.005, 0.01], \n",
    "              'reg_all':[0.02, 0.05, 0.1, 0.2], \n",
    "              'random_state':[1]}\n",
    "\n",
    "SVD_gs_2 = GridSearchCV(algo_class = SVD, \n",
    "                      param_grid = SVD_grid_2, \n",
    "                      measures=['rmse'], \n",
    "                      n_jobs = -2, \n",
    "                      joblib_verbose = 5)\n",
    "\n",
    "SVD_gs_2.fit(data)\n",
    "SVD_gs_2.best_params['rmse']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 1.1730\n",
      "MAE:  0.9222\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9222089772718052"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using best parameters in new model and only fiting train set\n",
    "svd_2 = SVD(n_factors=30, n_epochs= 50, lr_all=0.005, reg_all= 0.2, random_state=1)\n",
    "\n",
    "svd_2.fit(trainset)\n",
    "\n",
    "#getting predictions using testset\n",
    "SVD_pred_2 = svd_2.test(testset)\n",
    "\n",
    "# Root Mean Square Error and Mean Absolute Error\n",
    "accuracy.rmse(SVD_pred_2)\n",
    "accuracy.mae(SVD_pred_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVD Gridsearch 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-2)]: Using backend LokyBackend with 7 concurrent workers.\n",
      "[Parallel(n_jobs=-2)]: Done   4 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=-2)]: Done  58 tasks      | elapsed:    2.0s\n",
      "[Parallel(n_jobs=-2)]: Done 148 tasks      | elapsed:    6.1s\n",
      "[Parallel(n_jobs=-2)]: Done 162 out of 162 | elapsed:    6.9s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'n_factors': 10,\n",
       " 'n_epochs': 45,\n",
       " 'lr_all': 0.005,\n",
       " 'reg_all': 0.2,\n",
       " 'random_state': 1}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Setting hyperparameters around default values\n",
    "SVD_grid_3 = {'n_factors':[1, 4, 7, 10, 15, 20],\n",
    "           'n_epochs':[45, 46, 47, 48, 49, 50, 51, 52, 57],\n",
    "           'lr_all':[0.005],\n",
    "           'reg_all':[0.2], \n",
    "              'random_state':[1]}\n",
    "\n",
    "SVD_gs_3 = GridSearchCV(algo_class = SVD, \n",
    "                      param_grid = SVD_grid_3, \n",
    "                      measures=['rmse'], \n",
    "                      n_jobs = -2, \n",
    "                      joblib_verbose = 5, \n",
    "                       cv=3)\n",
    "\n",
    "SVD_gs_3.fit(data)\n",
    "SVD_gs_3.best_params['rmse']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 1.1718\n",
      "MAE:  0.9224\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.922388414722175"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using best parameters in new model and only fiting train set\n",
    "svd_3 = SVD(n_factors=10, n_epochs= 45, lr_all=0.005, reg_all= 0.2)\n",
    "\n",
    "svd_3.fit(trainset)\n",
    "\n",
    "#getting predictions using testset\n",
    "SVD_pred_3 = svd_3.test(testset)\n",
    "\n",
    "# Root Mean Square Error and Mean Absolute Error\n",
    "accuracy.rmse(SVD_pred_3)\n",
    "accuracy.mae(SVD_pred_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating RMSE of algorithm SVD on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    1.1812  1.1691  1.1567  1.1480  1.1813  1.1673  0.0132  \n",
      "RMSE (trainset)   0.8918  0.8938  0.8984  0.8990  0.8900  0.8946  0.0036  \n",
      "Fit time          0.26    0.25    0.26    0.26    0.25    0.26    0.00    \n",
      "Test time         0.01    0.01    0.01    0.01    0.01    0.01    0.00    \n"
     ]
    }
   ],
   "source": [
    "SVD_cv3 = cross_validate(algo = svd_3, \n",
    "                        data = data, \n",
    "                        measures=['RMSE'], \n",
    "                        cv=5, \n",
    "                        n_jobs=-2, \n",
    "                        verbose=True, \n",
    "                        return_train_measures=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Will move on to try a different algorithm, SVD++"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVD++"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 1.1785\n",
      "MAE:  0.9337\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9336873414189552"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Default hyperparameters\n",
    "svdpp_Model = SVDpp()\n",
    "\n",
    "svdpp_Model.fit(trainset)\n",
    "\n",
    "#getting predictions using testset\n",
    "SVDpp_pred = svdpp_Model.test(testset)\n",
    "\n",
    "# Root Mean Square Error and Mean Absolute Error\n",
    "accuracy.rmse(SVDpp_pred)\n",
    "accuracy.mae(SVDpp_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVD++ Gridsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-2)]: Using backend LokyBackend with 7 concurrent workers.\n",
      "[Parallel(n_jobs=-2)]: Done   4 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=-2)]: Done  58 tasks      | elapsed:    7.4s\n",
      "[Parallel(n_jobs=-2)]: Done 148 tasks      | elapsed:   22.8s\n",
      "[Parallel(n_jobs=-2)]: Done 274 tasks      | elapsed:   50.3s\n",
      "[Parallel(n_jobs=-2)]: Done 324 out of 324 | elapsed:  1.2min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'n_factors': 5, 'n_epochs': 20, 'reg_all': 0.05, 'lr_all': 0.01}"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SVDpp_grid = {'n_factors':[1, 5, 15, 30], \n",
    "              'n_epochs':[10, 20, 40], \n",
    "              'reg_all':[0.01, 0.02, 0.05], \n",
    "             'lr_all':[0.003, 0.007, 0.01]}\n",
    "\n",
    "\n",
    "SVDpp_gs = GridSearchCV(algo_class = SVDpp, \n",
    "                        param_grid = SVDpp_grid, \n",
    "                        measures=['rmse'], \n",
    "                        n_jobs = -2, \n",
    "                        cv=3, \n",
    "                        joblib_verbose = 5)\n",
    "\n",
    "\n",
    "SVDpp_gs.fit(data)\n",
    "SVDpp_gs.best_params['rmse']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 1.1745\n",
      "MAE:  0.9188\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9188277216952461"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Default hyperparameters\n",
    "svdpp_1 = SVDpp(n_factors=5, n_epochs=20, reg_all=0.05, lr_all=0.01)\n",
    "\n",
    "svdpp_1.fit(trainset)\n",
    "\n",
    "#getting predictions using testset\n",
    "SVDpp_pred_1 = svdpp_1.test(testset)\n",
    "\n",
    "# Root Mean Square Error and Mean Absolute Error\n",
    "accuracy.rmse(SVDpp_pred_1)\n",
    "accuracy.mae(SVDpp_pred_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVD++ Gridsearch 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-2)]: Using backend LokyBackend with 7 concurrent workers.\n",
      "[Parallel(n_jobs=-2)]: Done   4 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=-2)]: Done  58 tasks      | elapsed:    8.8s\n",
      "[Parallel(n_jobs=-2)]: Done 148 tasks      | elapsed:   23.9s\n",
      "[Parallel(n_jobs=-2)]: Done 162 out of 162 | elapsed:   26.3s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'n_factors': 3, 'n_epochs': 20, 'reg_all': 0.1, 'lr_all': 0.01}"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SVDpp_grid_2 = {'n_factors':[1, 3, 5, 7, 9, 10], \n",
    "              'n_epochs':[20], \n",
    "              'reg_all':[0.02, 0.05, 0.1], \n",
    "             'lr_all':[0.007, 0.01, 0.01]}\n",
    "\n",
    "\n",
    "SVDpp_gs_2 = GridSearchCV(algo_class = SVDpp, \n",
    "                        param_grid = SVDpp_grid_2, \n",
    "                        measures=['rmse'], \n",
    "                        n_jobs = -2, \n",
    "                        cv=3, \n",
    "                        joblib_verbose = 5)\n",
    "\n",
    "\n",
    "SVDpp_gs_2.fit(data)\n",
    "SVDpp_gs_2.best_params['rmse']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 1.1720\n",
      "MAE:  0.9198\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9197541826983862"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Default hyperparameters\n",
    "SVDpp_2 = SVDpp(n_factors=3, n_epochs=20, reg_all=0.1, lr_all=0.01)\n",
    "\n",
    "SVDpp_2.fit(trainset)\n",
    "\n",
    "#getting predictions using testset\n",
    "SVDpp_pred_2 = SVDpp_2.test(testset)\n",
    "\n",
    "# Root Mean Square Error and Mean Absolute Error\n",
    "accuracy.rmse(SVDpp_pred_2)\n",
    "accuracy.mae(SVDpp_pred_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating RMSE of algorithm SVDpp on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    1.1818  1.1697  1.1673  1.1453  1.1916  1.1711  0.0156  \n",
      "RMSE (trainset)   0.8993  0.9046  0.9051  0.9107  0.9037  0.9047  0.0037  \n",
      "Fit time          1.06    1.08    1.12    1.07    1.07    1.08    0.02    \n",
      "Test time         0.04    0.03    0.03    0.03    0.03    0.04    0.00    \n"
     ]
    }
   ],
   "source": [
    "SVDpp_2_cv = cross_validate(algo = SVDpp_2, \n",
    "                        data = data, \n",
    "                        measures=['RMSE'], \n",
    "                        cv=5, \n",
    "                        n_jobs=-2, \n",
    "                        verbose=True, \n",
    "                        return_train_measures=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to compare the performance of various recommendation models, I utilized the root mean square error (RMSE) as the evaluation metric. After analyzing the results, the SVD model with hyperparameters from the third grid search was the most effective, with an RMSE of 1.1718. This is lower than the RMSE of 1.7023 produced by the baseline model, indicating a marked improvement. Overall, the SVD model with the specified hyperparameters emerged as the clear choice for the best recommendation model based on its performance on the RMSE metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 1.7023\n",
      "RMSE: 1.1718\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "baseline_model_rmse = accuracy.rmse(base_pred)\n",
    "best_model_rmse = accuracy.rmse(SVD_pred_3)\n",
    "\n",
    "x = ['baseline', 'Best Model']\n",
    "y = [baseline_model_rmse, best_model_rmse]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,8))\n",
    "plt.bar(x, y, color=['Black', 'Green'])\n",
    "plt.ylim(0.7, 1.7)\n",
    "ax.set_title(\"Baseline vs Best SVD\")\n",
    "plt.ylabel('RMSE');\n",
    "# plt.savefig('images/suprise_models_bar.png', dpi=300, bbox_inches='tight');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "!ls data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import gzip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "vec_tfidf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def parse(path):\n",
    "  g = gzip.open(path, 'rb')\n",
    "  for l in g:\n",
    "    yield eval(l)\n",
    "\n",
    "def getDF(path):\n",
    "  i = 0\n",
    "  df = {}\n",
    "  for d in parse(path):\n",
    "    df[i] = d\n",
    "    i += 1\n",
    "  return pd.DataFrame.from_dict(df, orient='index')\n",
    "\n",
    "meta_df = getDF('./data/meta_Video_Games.json.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (learn-env)",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
